{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tqdm import tqdm\n",
    "from keras.utils import to_categorical\n",
    "from copy import copy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = pd.read_csv('db/dataset_entidades_actor_2.csv')\n",
    "data_c = pd.read_csv('db/dataset_entidades_company_2.csv')\n",
    "data_m = pd.read_csv('db/dataset_entidades_musical_artist_2.csv')\n",
    "data_p = pd.read_csv('db/dataset_entidades_politican_2.csv')\n",
    "data_s = pd.read_csv('db/dataset_entidades_soccer_player_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([data_a,data_c,data_m,data_p,data_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Anthony_Eustrel</td>\n",
       "      <td>['Person', 'Actor', 'Agent', 'Artist']</td>\n",
       "      <td>Actor</td>\n",
       "      <td>Anthony Eustrel (October 12, 1902-July 2, 1979...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Billy_Dee</td>\n",
       "      <td>['Person', 'Actor', 'AdultActor', 'Agent', 'Ar...</td>\n",
       "      <td>AdultActor</td>\n",
       "      <td>Not to be confused with Billy Dee Williams or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sid_Lucero</td>\n",
       "      <td>['Person', 'Actor', 'Agent', 'Artist']</td>\n",
       "      <td>Actor</td>\n",
       "      <td>Timothy Mark Pimentel Eigenmann, better known ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Jacques_Balutin</td>\n",
       "      <td>['Person', 'Actor', 'Agent', 'Artist']</td>\n",
       "      <td>Actor</td>\n",
       "      <td>Jacques Balutin is a French actor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Austin_Leigh</td>\n",
       "      <td>['Person', 'Actor', 'Agent', 'Artist']</td>\n",
       "      <td>Actor</td>\n",
       "      <td>Austin Leigh was a British stage and film actor.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            index  \\\n",
       "0           0  Anthony_Eustrel   \n",
       "1           1        Billy_Dee   \n",
       "2           2       Sid_Lucero   \n",
       "3           3  Jacques_Balutin   \n",
       "4           4     Austin_Leigh   \n",
       "\n",
       "                                                   0           1  \\\n",
       "0             ['Person', 'Actor', 'Agent', 'Artist']       Actor   \n",
       "1  ['Person', 'Actor', 'AdultActor', 'Agent', 'Ar...  AdultActor   \n",
       "2             ['Person', 'Actor', 'Agent', 'Artist']       Actor   \n",
       "3             ['Person', 'Actor', 'Agent', 'Artist']       Actor   \n",
       "4             ['Person', 'Actor', 'Agent', 'Artist']       Actor   \n",
       "\n",
       "                                                   2  \n",
       "0  Anthony Eustrel (October 12, 1902-July 2, 1979...  \n",
       "1  Not to be confused with Billy Dee Williams or ...  \n",
       "2  Timothy Mark Pimentel Eigenmann, better known ...  \n",
       "3                 Jacques Balutin is a French actor.  \n",
       "4   Austin Leigh was a British stage and film actor.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = all_data.groupby(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:01<00:00, 94.80it/s] \n"
     ]
    }
   ],
   "source": [
    "## Delete classes with few examples (<300)\n",
    "for item in tqdm(group_data):\n",
    "    target = item[0]\n",
    "    if len(all_data[all_data['1']==target])<300:\n",
    "        all_data.drop(all_data[all_data['1']==target].index,inplace=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_word_sequence(texts):\n",
    "    abstract_sentences = list()\n",
    "    for text in tqdm(texts):\n",
    "        abstract_sentences.append(text_to_word_sequence(str(text)))\n",
    "    return abstract_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = all_data.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = all_data.iloc[:,3].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Actor', 'AdultActor', 'Company', 'Congressman', 'Governor',\n",
       "       'Mayor', 'MemberOfParliament', 'MusicalArtist', 'Politician',\n",
       "       'President', 'PrimeMinister', 'SoccerManager', 'SoccerPlayer',\n",
       "       'VoiceActor'], dtype='<U18')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29033/29033 [00:00<00:00, 32204.10it/s]\n"
     ]
    }
   ],
   "source": [
    "abstract_sentences = text_word_sequence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(examples):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(examples)\n",
    "    sequences = tokenizer.texts_to_sequences(examples)\n",
    "    return (sequences, tokenizer)\n",
    "sequences, tokenizer = tokenize_text(abstract_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_sentences_number = sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16371789, 23699860)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(size=200, sg=1, workers=10)\n",
    "\n",
    "model.build_vocab(sentences=abstract_sentences)\n",
    "\n",
    "model.train(sentences=abstract_sentences, epochs=20, total_examples=len(abstract_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec_dbpedia_size=200.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/83123 [00:00<?, ?it/s]/home/mobility/anaconda/envs/michael_env/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/home/mobility/anaconda/envs/michael_env/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "100%|██████████| 83123/83123 [00:00<00:00, 249975.90it/s]\n"
     ]
    }
   ],
   "source": [
    "quantity_of_embeddings = len(model.wv.vocab)\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index), 200))\n",
    "for word, i in tqdm(tokenizer.word_index.items()):\n",
    "    if word in model and i < quantity_of_embeddings:\n",
    "        embedding_matrix[i] = model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_sequences= list()\n",
    "# for i,items in tqdm(enumerate(abstract_sentences_number,0)):\n",
    "#     partial = list()\n",
    "#     for j in items:\n",
    "#         if j in model:\n",
    "#             partial.append(j)\n",
    "#     final_sequences.append(partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29033, 29033)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstract_sentences_number), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sequences_pad = pad_sequences(abstract_sentences_number,maxlen=100)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(sequences_pad,y,test_size=0.10, random_state=42)\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((83123, 200), (20903, 100))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding,Input, Conv1D, MaxPooling1D, Dense,merge,Flatten, Dropout, GlobalMaxPool1D, Concatenate\n",
    "from keras.initializers import random_uniform\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "channels = 100\n",
    "size_feature_map = 3\n",
    "size_feature_map_2 = 4\n",
    "size_feature_map_3 = 5\n",
    "dropout = 0.25\n",
    "dense1 = 50\n",
    "dense2 = 100\n",
    "embedding_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequence_input (InputLayer)  (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 100, 200)          16624600  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 100, 100)          60100     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 100, 100)          40100     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                714       \n",
      "=================================================================\n",
      "Total params: 16,740,664\n",
      "Trainable params: 16,740,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20903 samples, validate on 5226 samples\n",
      "Epoch 1/50\n",
      "20903/20903 [==============================] - 14s 661us/step - loss: 0.9775 - acc: 0.6960 - val_loss: 0.6443 - val_acc: 0.7968\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79679, saving model to weights-best-model1-dbpedia.hdf5\n",
      "Epoch 2/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.5988 - acc: 0.8086 - val_loss: 0.5700 - val_acc: 0.8171\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.79679 to 0.81707, saving model to weights-best-model1-dbpedia.hdf5\n",
      "Epoch 3/50\n",
      "20903/20903 [==============================] - 11s 516us/step - loss: 0.5308 - acc: 0.8286 - val_loss: 0.5344 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.81707 to 0.82472, saving model to weights-best-model1-dbpedia.hdf5\n",
      "Epoch 4/50\n",
      "20903/20903 [==============================] - 11s 514us/step - loss: 0.4876 - acc: 0.8419 - val_loss: 0.5233 - val_acc: 0.8307\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.82472 to 0.83065, saving model to weights-best-model1-dbpedia.hdf5\n",
      "Epoch 5/50\n",
      "20903/20903 [==============================] - 11s 514us/step - loss: 0.4486 - acc: 0.8545 - val_loss: 0.5303 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.83065\n",
      "Epoch 6/50\n",
      "20903/20903 [==============================] - 11s 514us/step - loss: 0.4161 - acc: 0.8655 - val_loss: 0.5282 - val_acc: 0.8257\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.83065\n",
      "Epoch 7/50\n",
      "20903/20903 [==============================] - 11s 514us/step - loss: 0.3801 - acc: 0.8773 - val_loss: 0.5812 - val_acc: 0.8241\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.83065\n",
      "Epoch 8/50\n",
      "20903/20903 [==============================] - 11s 514us/step - loss: 0.3732 - acc: 0.8806 - val_loss: 0.5749 - val_acc: 0.8253\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.83065\n",
      "Epoch 9/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3491 - acc: 0.8875 - val_loss: 0.5953 - val_acc: 0.8241\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.83065\n",
      "Epoch 10/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3413 - acc: 0.8891 - val_loss: 0.6573 - val_acc: 0.8136\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.83065\n",
      "Epoch 11/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3375 - acc: 0.8913 - val_loss: 0.6319 - val_acc: 0.8245\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.83065\n",
      "Epoch 12/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3341 - acc: 0.8922 - val_loss: 0.6334 - val_acc: 0.8236\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.83065\n",
      "Epoch 13/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3307 - acc: 0.8935 - val_loss: 0.6543 - val_acc: 0.8219\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.83065\n",
      "Epoch 14/50\n",
      "20903/20903 [==============================] - 11s 514us/step - loss: 0.3257 - acc: 0.8952 - val_loss: 0.6755 - val_acc: 0.8213\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.83065\n",
      "Epoch 15/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3279 - acc: 0.8938 - val_loss: 0.7030 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.83065\n",
      "Epoch 16/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3319 - acc: 0.8926 - val_loss: 0.7037 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.83065\n",
      "Epoch 17/50\n",
      "20903/20903 [==============================] - 11s 516us/step - loss: 0.3272 - acc: 0.8940 - val_loss: 0.6984 - val_acc: 0.8266\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.83065\n",
      "Epoch 18/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3275 - acc: 0.8940 - val_loss: 0.7542 - val_acc: 0.8224\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.83065\n",
      "Epoch 19/50\n",
      "20903/20903 [==============================] - 11s 516us/step - loss: 0.3228 - acc: 0.8952 - val_loss: 0.7408 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.83065\n",
      "Epoch 20/50\n",
      "20903/20903 [==============================] - 11s 514us/step - loss: 0.3280 - acc: 0.8941 - val_loss: 0.7761 - val_acc: 0.8241\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.83065\n",
      "Epoch 21/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3257 - acc: 0.8948 - val_loss: 0.7685 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.83065\n",
      "Epoch 22/50\n",
      "20903/20903 [==============================] - 11s 513us/step - loss: 0.3259 - acc: 0.8948 - val_loss: 0.7745 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.83065\n",
      "Epoch 23/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3238 - acc: 0.8958 - val_loss: 0.7539 - val_acc: 0.8131\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.83065\n",
      "Epoch 24/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3233 - acc: 0.8949 - val_loss: 0.7670 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.83065\n",
      "Epoch 25/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3226 - acc: 0.8957 - val_loss: 0.7730 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.83065\n",
      "Epoch 26/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3248 - acc: 0.8952 - val_loss: 0.7564 - val_acc: 0.8197\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.83065\n",
      "Epoch 27/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3213 - acc: 0.8961 - val_loss: 0.7909 - val_acc: 0.8184\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.83065\n",
      "Epoch 28/50\n",
      "20903/20903 [==============================] - 11s 516us/step - loss: 0.3243 - acc: 0.8955 - val_loss: 0.7962 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.83065\n",
      "Epoch 29/50\n",
      "20903/20903 [==============================] - 11s 514us/step - loss: 0.3187 - acc: 0.8962 - val_loss: 0.8402 - val_acc: 0.8188\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.83065\n",
      "Epoch 30/50\n",
      "20903/20903 [==============================] - 11s 515us/step - loss: 0.3242 - acc: 0.8954 - val_loss: 0.9410 - val_acc: 0.8102\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.83065\n",
      "Epoch 31/50\n",
      "20903/20903 [==============================] - 11s 516us/step - loss: 0.3246 - acc: 0.8951 - val_loss: 0.7885 - val_acc: 0.8203\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.83065\n",
      "Epoch 32/50\n",
      "20903/20903 [==============================] - 11s 514us/step - loss: 0.3221 - acc: 0.8958 - val_loss: 0.8414 - val_acc: 0.8071\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.83065\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20903/20903 [==============================] - 11s 516us/step - loss: 0.3181 - acc: 0.8967 - val_loss: 0.8227 - val_acc: 0.8207\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.83065\n",
      "Epoch 34/50\n",
      "20903/20903 [==============================] - 11s 514us/step - loss: 0.3202 - acc: 0.8960 - val_loss: 0.9490 - val_acc: 0.8123\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.83065\n",
      "Epoch 35/50\n",
      "14656/20903 [====================>.........] - ETA: 3s - loss: 0.3264 - acc: 0.8942"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bdbb84a7de1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights-best-model1-dbpedia.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(tokenizer.word_index),\n",
    "                            200,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=True)\n",
    "\n",
    "sequence_input = Input(shape=(embedding_size,), dtype='int32', name='sequence_input')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "embedded_sequences = Dropout(dropout) (embedded_sequences)\n",
    "x = Conv1D(channels, size_feature_map, activation='relu',padding='SAME')(embedded_sequences)\n",
    "x = Conv1D(channels, size_feature_map_2,activation='relu',padding='SAME')(x)\n",
    "x = Dropout(dropout)(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "# x = Flatten()(x)\n",
    "\n",
    "fc1 = Dense(dense2, activation='relu', name='fc1')(x)\n",
    "fc1 = Dropout(dropout)(fc1)\n",
    "fc2 = Dense(dense1, activation='relu', name='fc2')(fc1)\n",
    "preds = Dense(14, activation=(tf.nn.softmax))(fc2)\n",
    "model_cnn = Model(sequence_input, preds)\n",
    "model_cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_cnn.summary()\n",
    "checkpoint = ModelCheckpoint('weights-best-model1-dbpedia.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "model_cnn.fit(x_train, y_train, batch_size=64, epochs=50,validation_data=(x_val,y_val),verbose=1,callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 1s 259us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5377920292543642, 0.8240358126721763]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.load_weights('weights-best-model1-dbpedia.hdf5')\n",
    "model_cnn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 82us/step\n"
     ]
    }
   ],
   "source": [
    "predicted = model_cnn.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predicted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
