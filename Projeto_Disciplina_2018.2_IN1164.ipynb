{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto disciplina IN1164\n",
    "<p> Alunos: Everaldo Costa Neto </p>\n",
    "<p>         Michael Oliveira da Cruz </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn import preprocessing\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantities_of_entities = 100\n",
    "embedding_size = 300\n",
    "batch_size = 128\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('file_output_1000_example1.csv')\n",
    "data2 = pd.read_csv('file_output_1000_example2.csv')\n",
    "data3 = pd.read_csv('file_output_1000_example3.csv')\n",
    "data4 = pd.read_csv('file_output_1000_example4.csv')\n",
    "data5 = pd.read_csv('file_output_1000_example5.csv')\n",
    "metacritics_album = pd.read_csv('arquivos_experimentos/output_abstract_metacritic_album.csv')\n",
    "metacritics_album = metacritics_album.iloc[:,1:]\n",
    "metacritics_album.dropna(inplace=True)\n",
    "metacritics_movies = pd.read_csv('arquivos_experimentos/output_abstract_metacritic_movies.csv')\n",
    "metacritics_movies = metacritics_movies.iloc[:,1:]\n",
    "metacritics_movies.dropna(inplace=True)\n",
    "cities = pd.read_csv('arquivos_experimentos/output_abstract_cities.csv')\n",
    "cities = cities.iloc[:,1:]\n",
    "cities.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacritic_target = list()\n",
    "for i in range(metacritics_album.shape[0]):\n",
    "    metacritic_target.append(ast.literal_eval(metacritics_album.iloc[i,1])[0])\n",
    "metacritics_album['class_target'] = metacritic_target\n",
    "metacritics_album.rename({'types':'other_class'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacritic_movie_target = list()\n",
    "for i in range(metacritics_movies.shape[0]):\n",
    "    metacritic_movie_target.append(ast.literal_eval(metacritics_movies.iloc[i,1])[0])\n",
    "metacritics_movies['class_target'] = metacritic_movie_target\n",
    "metacritics_movies.rename({'types':'other_class'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_target = list()\n",
    "for i in range(cities.shape[0]):\n",
    "    cities_target.append(ast.literal_eval(cities.iloc[i,1])[0])\n",
    "cities['class_target'] = cities_target\n",
    "cities.rename({'types':'other_class'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 1799, 1520)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cities), len(metacritics_movies), len(metacritics_album)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data after some cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mobility/anaconda/envs/michael_env/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([data1,data2,data3,data4,data5,metacritics_album,metacritics_movies,cities])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throwing out data with labels less than \"quantities_of_entites\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_classes = list()\n",
    "for row,value in data.groupby('class_target'):\n",
    "    if value.shape[0] < quantities_of_entities:\n",
    "        few_classes.append(value.class_target.values[0])\n",
    "\n",
    "for item in few_classes:\n",
    "    data = data[data['class_target'] != item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data: examples and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = data.abstract.values\n",
    "target = data.class_target.values\n",
    "entities = data.entity.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319618"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throwing out data which don't have in rdf2vec\n",
    "### obs: This step is just necessary to use the model that use rdf embeddings. Otherwise, jump to step: sequences abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rdf = word2vec.Word2Vec.load('DB2Vec_sg_500_5_5_15_4_500', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rdf(decoder):\n",
    "    x = list()\n",
    "    idx = list()\n",
    "    for i in tqdm(range(len(decoder))):\n",
    "        text = 'dbr:'+decoder[i]\n",
    "        if text in model_rdf:\n",
    "            x.append(model_rdf[text])\n",
    "        else:\n",
    "            idx.append(i)\n",
    "    return x, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/319618 [00:00<?, ?it/s]/home/mobility/anaconda/envs/michael_env/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/home/mobility/anaconda/envs/michael_env/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n",
      "100%|██████████| 319618/319618 [00:03<00:00, 83308.76it/s]\n"
     ]
    }
   ],
   "source": [
    "rdf_embeddings, idx_remove = map_rdf(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319618/319618 [02:54<00:00, 1831.97it/s]\n"
     ]
    }
   ],
   "source": [
    "x_example = list()\n",
    "y_target = list()\n",
    "for idx in tqdm(range(entities.shape[0])):\n",
    "    if idx not in idx_remove:\n",
    "        x_example.append(examples[idx])\n",
    "        y_target.append(target[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The KL Monorail Line is an urban monorail system in Kuala Lumpur, Malaysia. It opened on 31 August 2003, with 11 stations running 8.6 km (5 mi) on two parallel elevated tracks. It connects the Kuala Lumpur Sentral transport hub with the \"Golden Triangle\". It was completed at a cost of MYR 1.18 billion by the KL Infrastructure Group (KL Infra). The line is one of the components of the Klang Valley Integrated Transit System.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_example[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269902,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = x_example\n",
    "target = y_target\n",
    "len(examples),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence of abstracts\n",
    "$$\n",
    "abstract\\_sentences = [['the','word'],['French']]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269902/269902 [00:11<00:00, 22951.92it/s]\n"
     ]
    }
   ],
   "source": [
    "def text_word_sequence(texts):\n",
    "    abstract_sentences = list()\n",
    "    for text in tqdm(texts):\n",
    "        abstract_sentences.append(text_to_word_sequence(text))\n",
    "    return abstract_sentences\n",
    "abstract_sentences = text_word_sequence(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269902"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstract_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating embeddings through word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376743522, 498328840)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(size=embedding_size, sg=1, workers=10)\n",
    "\n",
    "model.build_vocab(sentences=abstract_sentences)\n",
    "\n",
    "model.train(sentences=abstract_sentences, epochs=20, total_examples=len(abstract_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_of_embeddings = len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113417"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantity_of_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(quantity_of_embeddings, examples):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(examples)\n",
    "    sequences = tokenizer.texts_to_sequences(examples)\n",
    "    return (sequences, tokenizer)\n",
    "sequences, tokenizer = tokenize_text(quantity_of_embeddings,examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 92.32 words (96.832780)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Review length: \")\n",
    "result = [len(x) for x in sequences]\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))\n",
    "# plot review length\n",
    "plt.boxplot(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508268, 300, 269902, 226150)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index), embedding_size, len(examples), len(list(set(examples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Matrix\n",
    "Words not found in embedding index will be all-zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/508268 [00:00<?, ?it/s]/home/mobility/anaconda/envs/michael_env/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/mobility/anaconda/envs/michael_env/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n",
      "100%|██████████| 508268/508268 [00:02<00:00, 207036.69it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(tokenizer.word_index), embedding_size))\n",
    "for word, i in tqdm(tokenizer.word_index.items()):\n",
    "    if word in model and i < quantity_of_embeddings:\n",
    "        embedding_matrix[i] = model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(target))\n",
    "quantity_of_targets = len(np.unique(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((508268, 300), 221)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape,quantity_of_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269902, 269902)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences), len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data in train, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "encoder = preprocessing.LabelBinarizer()\n",
    "labels = encoder.fit_transform(target)\n",
    "\n",
    "sequences_pad = pad_sequences(sequences,maxlen=embedding_size)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(sequences_pad,labels,test_size=0.10, random_state=42, stratify=labels)\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train, test_size=0.2,random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_rdf = np.array(rdf_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rdf,x_test_rdf,y_train_rdf,y_test_rdf = train_test_split(examples_rdf,labels,test_size=0.10, random_state=42, stratify=labels)\n",
    "\n",
    "x_train_rdf,x_val_rdf,y_train_rdf,y_val_rdf = train_test_split(x_train_rdf,y_train_rdf, test_size=0.2,random_state=42, stratify=y_train_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_rdf_norm = np.array([np.linalg.norm(vetor) for vetor in x_train_rdf])\n",
    "y_val_rdf_norm = np.array([np.linalg.norm(vetor) for vetor in x_val_rdf])\n",
    "y_test_rdf_norm = np.array([np.linalg.norm(vetor) for vetor in x_test_rdf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding,Input, Conv1D, MaxPooling1D, Dense,merge,Flatten, Dropout, GlobalMaxPool1D, Concatenate\n",
    "from keras.initializers import random_uniform\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "channels = 100\n",
    "size_feature_map = 3\n",
    "size_feature_map_2 = 4\n",
    "size_feature_map_3 = 5\n",
    "dropout = 0.25\n",
    "dense1 = 50\n",
    "dense2 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a86bdbe50f2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m embedding_layer = Embedding(len(tokenize.word_index),\n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             trainable=False)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize' is not defined"
    "              metrics=['acc'])\n",
    "\n",
    "model_cnn.summary()\n",
    "checkpoint = ModelCheckpoint('weights-best-model1.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "model_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,validation_data=(x_val,y_val),verbose=1,callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence_input (InputLayer)     (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 300, 300)     152480400   sequence_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 300, 300)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 300, 100)     90100       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 300, 100)     120100      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 300, 100)     150100      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 100, 100)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 75, 100)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 60, 100)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 50, 100)      0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 38, 100)      0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 30, 100)      0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 5000)         0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3800)         0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 3000)         0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 11800)        0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 100)          1180100     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 221)          22321       fc1[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 154,043,121\n",
      "Trainable params: 1,562,721\n",
      "Non-trainable params: 152,480,400\n",
      "__________________________________________________________________________________________________\n",
      "Train on 194328 samples, validate on 48583 samples\n",
      "Epoch 1/20\n",
      "194328/194328 [==============================] - 128s 657us/step - loss: 1.7088 - acc: 0.5577 - val_loss: 0.9971 - val_acc: 0.7029\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70288, saving model to weights-best-model2.hdf5\n",
      "Epoch 2/20\n",
      "194328/194328 [==============================] - 127s 654us/step - loss: 0.8765 - acc: 0.7210 - val_loss: 0.8650 - val_acc: 0.7274\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.70288 to 0.72737, saving model to weights-best-model2.hdf5\n",
      "Epoch 3/20\n",
      "194328/194328 [==============================] - 127s 655us/step - loss: 0.7438 - acc: 0.7504 - val_loss: 0.8232 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.72737 to 0.73268, saving model to weights-best-model2.hdf5\n",
      "Epoch 4/20\n",
      "194328/194328 [==============================] - 127s 655us/step - loss: 0.6667 - acc: 0.7691 - val_loss: 0.8142 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.73268\n",
      "Epoch 5/20\n",
      "194328/194328 [==============================] - 127s 655us/step - loss: 0.6158 - acc: 0.7808 - val_loss: 0.8288 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73268\n",
      "Epoch 6/20\n",
      "194328/194328 [==============================] - 127s 655us/step - loss: 0.5797 - acc: 0.7909 - val_loss: 0.8304 - val_acc: 0.7304\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.73268\n",
      "Epoch 7/20\n",
      " 60416/194328 [========>.....................] - ETA: 1:20 - loss: 0.5278 - acc: 0.8079"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-916b04e8a959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights-best-model2.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2670\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2654\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(tokenizer.word_index),\n",
    "                            embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(embedding_size,), dtype='int32', name='sequence_input')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "embedded_sequences = Dropout(dropout) (embedded_sequences)\n",
    "x = Conv1D(channels, size_feature_map, activation='relu',padding='SAME')(embedded_sequences)\n",
    "x = MaxPooling1D(3, padding='SAME')(x)\n",
    "\n",
    "y = Conv1D(channels, size_feature_map_2, activation='relu',padding='SAME')(embedded_sequences)\n",
    "y = MaxPooling1D(4, padding='SAME')(y)\n",
    "\n",
    "z = Conv1D(channels, size_feature_map_3, activation='relu',padding='SAME')(embedded_sequences)\n",
    "z = MaxPooling1D(5, padding='SAME')(z)\n",
    "\n",
    "x = MaxPooling1D(2, padding='SAME')(x)\n",
    "y = MaxPooling1D(2, padding='SAME')(y)\n",
    "z = MaxPooling1D(2, padding='SAME')(z)\n",
    "\n",
    "x = Flatten()(x)      \n",
    "y = Flatten()(y)\n",
    "z = Flatten()(z)\n",
    "\n",
    "\n",
    "conc = concatenate([x,y,z],axis=1)\n",
    "fc1 = Dense(100, activation='relu', name='fc1')(conc)\n",
    "preds = Dense(quantity_of_targets, activation='softmax')(fc1)\n",
    "model_cnn = Model(sequence_input, preds)\n",
    "model_cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_cnn.summary()\n",
    "checkpoint = ModelCheckpoint('weights-best-model2.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "model_cnn.fit(x_train,y_train, batch_size=batch_size, epochs=epochs,validation_data=(x_val,y_val),verbose=1,callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence_input (InputLayer)     (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 300, 300)     152480400   sequence_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 300, 300)     0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 300, 100)     90100       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 150, 100)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rdf_input (InputLayer)          (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 15000)        0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           25050       rdf_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 15050)        0           flatten_6[0][0]                  \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 100)          1505100     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 221)          22321       fc1[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 154,122,971\n",
      "Trainable params: 1,642,571\n",
      "Non-trainable params: 152,480,400\n",
      "__________________________________________________________________________________________________\n",
      "Train on 194328 samples, validate on 48583 samples\n",
      "Epoch 1/20\n",
      "194328/194328 [==============================] - 52s 269us/step - loss: 1.4947 - acc: 0.5955 - val_loss: 0.7720 - val_acc: 0.7364\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.73643, saving model to weights-best-model3.hdf5\n",
      "Epoch 2/20\n",
      "194328/194328 [==============================] - 52s 268us/step - loss: 0.6451 - acc: 0.7686 - val_loss: 0.6668 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.73643 to 0.76185, saving model to weights-best-model3.hdf5\n",
      "Epoch 3/20\n",
      "194328/194328 [==============================] - 52s 268us/step - loss: 0.5216 - acc: 0.7994 - val_loss: 0.6379 - val_acc: 0.7598\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.76185\n",
      "Epoch 4/20\n",
      "194328/194328 [==============================] - 52s 268us/step - loss: 0.4544 - acc: 0.8161 - val_loss: 0.6257 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.76185 to 0.76640, saving model to weights-best-model3.hdf5\n",
      "Epoch 5/20\n",
      "194328/194328 [==============================] - 52s 268us/step - loss: 0.4114 - acc: 0.8285 - val_loss: 0.6449 - val_acc: 0.7594\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.76640\n",
      "Epoch 6/20\n",
      " 66432/194328 [=========>....................] - ETA: 31s - loss: 0.3593 - acc: 0.8458"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-f562a1a22a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights-best-model3.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_rdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_val_rdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2670\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/michael_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2654\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(tokenizer.word_index),\n",
    "                            embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(embedding_size,), dtype='int32', name='sequence_input')\n",
    "rdf_input = Input(shape=(x_train_rdf.shape[1],), dtype='float32', name='rdf_input')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "embedded_sequences = Dropout(dropout) (embedded_sequences)\n",
    "x = Conv1D(channels, size_feature_map, activation='relu',padding='SAME')(embedded_sequences)\n",
    "x_rdf = Dense(dense1, activation='relu',)(rdf_input)\n",
    "\n",
    "\n",
    "x = MaxPooling1D(2, padding='SAME')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "\n",
    "x = concatenate([x,x_rdf])\n",
    "\n",
    "\n",
    "fc1 = Dense(dense2, activation='relu', name='fc1')(x)\n",
    "\n",
    "preds = Dense(quantity_of_targets, activation='softmax')(fc1)\n",
    "model_cnn = Model([sequence_input,rdf_input], preds)\n",
    "model_cnn.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_cnn.summary()\n",
    "checkpoint = ModelCheckpoint('weights-best-model3.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "model_cnn.fit([x_train, x_train_rdf],y_train, batch_size=batch_size, epochs=epochs,validation_data=([x_val,x_val_rdf],y_val),verbose=1,callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequence_input (InputLayer)  (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 300, 300)          152480400 \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 300, 100)          90100     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 30000)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 100)               3000100   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 155,570,701\n",
      "Trainable params: 3,090,301\n",
      "Non-trainable params: 152,480,400\n",
      "_________________________________________________________________\n",
      "Train on 194328 samples, validate on 48583 samples\n",
      "Epoch 1/20\n",
      "194328/194328 [==============================] - 64s 328us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03689, saving model to weights-best-model4_regressao.hdf5\n",
      "Epoch 2/20\n",
      "194328/194328 [==============================] - 64s 329us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03689\n",
      "Epoch 3/20\n",
      "194328/194328 [==============================] - 65s 334us/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03689 to 0.03201, saving model to weights-best-model4_regressao.hdf5\n",
      "Epoch 4/20\n",
      "194328/194328 [==============================] - 65s 335us/step - loss: 0.0223 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03201 to 0.02981, saving model to weights-best-model4_regressao.hdf5\n",
      "Epoch 5/20\n",
      "194328/194328 [==============================] - 64s 331us/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02981\n",
      "Epoch 6/20\n",
      "194328/194328 [==============================] - 65s 336us/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02981 to 0.02927, saving model to weights-best-model4_regressao.hdf5\n",
      "Epoch 7/20\n",
      "194328/194328 [==============================] - 65s 337us/step - loss: 0.0173 - acc: 0.0000e+00 - val_loss: 0.0279 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02927 to 0.02793, saving model to weights-best-model4_regressao.hdf5\n",
      "Epoch 8/20\n",
      "194328/194328 [==============================] - 66s 338us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02793\n",
      "Epoch 9/20\n",
      "194328/194328 [==============================] - 63s 326us/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02793\n",
      "Epoch 10/20\n",
      "194328/194328 [==============================] - 66s 342us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02793 to 0.02480, saving model to weights-best-model4_regressao.hdf5\n",
      "Epoch 11/20\n",
      "194328/194328 [==============================] - 66s 341us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02480\n",
      "Epoch 12/20\n",
      "194328/194328 [==============================] - 63s 326us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02480\n",
      "Epoch 13/20\n",
      "194328/194328 [==============================] - 66s 339us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02480\n",
      "Epoch 14/20\n",
      "194328/194328 [==============================] - 63s 326us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02480\n",
      "Epoch 15/20\n",
      "194328/194328 [==============================] - 64s 330us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02480\n",
      "Epoch 16/20\n",
      "194328/194328 [==============================] - 65s 336us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02480\n",
      "Epoch 17/20\n",
      "194328/194328 [==============================] - 64s 327us/step - loss: 0.0104 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02480\n",
      "Epoch 18/20\n",
      "194328/194328 [==============================] - 66s 340us/step - loss: 0.0101 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02480\n",
      "Epoch 19/20\n",
      "194328/194328 [==============================] - 64s 328us/step - loss: 0.0098 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02480\n",
      "Epoch 20/20\n",
      "194328/194328 [==============================] - 65s 336us/step - loss: 0.0094 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e3cd14198>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(tokenizer.word_index),\n",
    "                            embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(embedding_size,), dtype='int32', name='sequence_input')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "embedded_sequences = Dropout(dropout) (embedded_sequences)\n",
    "x = Conv1D(channels, size_feature_map, activation='relu',padding='SAME', kernel_initializer='normal')(embedded_sequences)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "fc1 = Dense(dense2, activation='relu', name='fc1', kernel_initializer='normal')(x)\n",
    "preds = Dense(1,kernel_initializer='normal')(fc1)\n",
    "model_cnn = Model(sequence_input, preds)\n",
    "model_cnn.compile(loss='mean_squared_logarithmic_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_cnn.summary()\n",
    "checkpoint = ModelCheckpoint('weights-best-model4_regressao.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model_cnn.fit(x_train, y_train_rdf_norm, batch_size=batch_size, epochs=epochs,validation_data=(x_val,y_val_rdf_norm),verbose=1,callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5705"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del model_cnn\n",
    "del embedding_layer\n",
    "del embedded_sequences\n",
    "del sequence_input\n",
    "del x\n",
    "del fc1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26991/26991 [==============================] - 4s 139us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6348761475339395, 0.7658849246044978]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.load_weights('weights-best-model3.hdf5')\n",
    "model_cnn.evaluate([x_test,x_test_rdf], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'weights-best-model1.hdf5'\n",
    "#[0.9469769184396645, 0.7007891519417437]\n",
    "#[0.8864389452534648, 0.7139046348849177] with trainable embedding\n",
    "#'weights-best-model2.hdf5'\n",
    "#[0.8351280965102279, 0.734578192735327]\n",
    "#[0.8531569180732914, 0.7267607721114299] with trainable embedding\n",
    "#'weights-best-model3.hdf5'\n",
    "#[0.640283066827544, 0.7662183690926165]\n",
    "#[0.6486905805372122, 0.7575858619584013] with trainable embedding\n",
    "#'weights-best-model4_regressao.hdf5'\n",
    "#[0.024806722058497748, 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottleneck layer models\n",
    "### Obs: Here we can use the models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0943da5d8490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fc1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "model2 = Model(model_cnn.input, model_cnn.get_layer('fc1').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing bases to feed the models to extract the features\n",
    "### Ex:cities, movies a and album\n",
    "\n",
    "<p> After execute the lines below, all embeddings will be save and the evaluation with rdfs_script can be used. </p>\n",
    "<p> Just remember that embeddings extracted is related to one model. We didn't automatize to generate all embeddings </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_cities, _= tokenize_text(quantity_of_embeddings,cities.abstract.values)\n",
    "pad_sequences_cities = pad_sequences(sequences_cities,maxlen=embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_movies, _= tokenize_text(quantity_of_embeddings,metacritics_movies.abstract.values)\n",
    "pad_sequences_movies = pad_sequences(sequences_movies,maxlen=embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_album, _= tokenize_text(quantity_of_embeddings,metacritics_album.abstract.values)\n",
    "pad_sequences_album = pad_sequences(sequences_album,maxlen=embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_cities = cities.entity.values\n",
    "entities_movies = metacritics_movies.entity.values\n",
    "entities_album = metacritics_album.entity.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/154 [00:00<?, ?it/s]/home/mobility/anaconda/envs/michael_env/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/home/mobility/anaconda/envs/michael_env/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "100%|██████████| 154/154 [00:00<00:00, 25596.31it/s]\n",
      "100%|██████████| 1799/1799 [00:00<00:00, 33853.56it/s]\n",
      "100%|██████████| 1520/1520 [00:00<00:00, 44376.75it/s]\n"
     ]
    }
   ],
   "source": [
    "rdf_cities, idx_remove = map_rdf(entities_cities)\n",
    "rdf_movies, idx_remove_movies = map_rdf(entities_movies)\n",
    "rdf_album, idx_remove_album = map_rdf(entities_album)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences_movies = pad_sequences_movies.tolist()\n",
    "pad_sequences_movies.pop(idx_remove_movies[0])\n",
    "pad_sequences_movies = np.array(pad_sequences_movies)\n",
    "entities_movies = entities_movies.tolist()\n",
    "entities_movies = entities_movies.pop(idx_remove_movies[0])\n",
    "len(entities_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_cities = np.array(rdf_cities)\n",
    "rdf_movies = np.array(rdf_movies)\n",
    "rdf_album = np.array(rdf_album)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 500)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf_cities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddies_cities_final = model2.predict(pad_sequences_cities)\n",
    "embeddies_movie_final = model2.predict(pad_sequences_movies)\n",
    "embeddies_album_final = model2.predict(pad_sequences_album)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_embedding_dict(entity,embedding):\n",
    "    embeddies_dict_final = dict()\n",
    "    for i in range(len(entity)):\n",
    "        embeddies_dict_final['dbo:'+entity[i]] = embedding[i]\n",
    "    return embeddies_dict_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('embeddings/cities_embeddings_300w2v_norm_rdf_1l_100fc1.npy',assemble_embedding_dict(entities_cities,embeddies_cities_final))\n",
    "np.save('embeddings/movie_embeddings_300w2v_norm_rdf_trained_rdf_1l_100fc1.npy',assemble_embedding_dict(entities_movies,embeddies_movie_final))\n",
    "np.save('embeddings/album_embeddings_300w2v_norm_rdf_trained_rdf_1l_100fc1.npy',assemble_embedding_dict(entities_album,embeddies_album_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
